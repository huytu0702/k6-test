# PHASE 5: T·ª∞ ƒê·ªòNG H√ìA V√Ä MONITORING - B√ÅO C√ÅO CHI TI·∫æT

## üìã T·ªïng quan Phase 5

Phase 5 t·∫≠p trung v√†o vi·ªác x√¢y d·ª±ng h·ªá th·ªëng monitoring v√† automation cho K6 testing, bao g·ªìm:
- Real-time monitoring v√† custom metrics
- Aggregation v√† visualization c·ªßa test results
- Alerting system t·ª± ƒë·ªông
- K6 Cloud integration
- Dashboard v√† reporting tools

---

## 4.8 MONITORING V√Ä ALERTING

### 4.8.1 K·∫øt n·ªëi K6 v·ªõi Monitoring Systems

K6 h·ªó tr·ª£ nhi·ªÅu output formats v√† monitoring backends kh√°c nhau. Ch√∫ng ta ƒë√£ tri·ªÉn khai c√°c gi·∫£i ph√°p sau:

#### A. Local Monitoring v·ªõi JSON Output

**C√°ch s·ª≠ d·ª•ng:**
```bash
# Xu·∫•t k·∫øt qu·∫£ sang JSON
./k6-v0.52.0-windows-amd64/k6.exe run --out json=results/test-result.json scripts/load-test.js

# Xu·∫•t nhi·ªÅu formats c√πng l√∫c
./k6-v0.52.0-windows-amd64/k6.exe run \
  --out json=results/test.json \
  --out csv=results/test.csv \
  scripts/load-test.js
```

**Output Format:**
K6 s·ª≠ d·ª•ng NDJSON (Newline-Delimited JSON) format:
```json
{"type":"Metric","data":{"name":"http_reqs","type":"counter"},"metric":"http_reqs"}
{"metric":"http_reqs","type":"Point","data":{"time":"2025-11-24T01:32:09Z","value":1}}
{"type":"Metric","data":{"name":"http_req_duration","type":"trend"},"metric":"http_req_duration"}
{"metric":"http_req_duration","type":"Point","data":{"time":"2025-11-24T01:32:09Z","value":246.73}}
```

**∆Øu ƒëi·ªÉm:**
- ‚úÖ Ho√†n to√†n offline, kh√¥ng c·∫ßn external services
- ‚úÖ D·ªÖ parse v√† ph√¢n t√≠ch
- ‚úÖ C√≥ th·ªÉ version control
- ‚úÖ Mi·ªÖn ph√≠

**Nh∆∞·ª£c ƒëi·ªÉm:**
- ‚ùå Kh√¥ng c√≥ real-time visualization
- ‚ùå C·∫ßn t·ª± build dashboard
- ‚ùå File size l·ªõn v·ªõi long-running tests

#### B. K6 Cloud (SaaS Solution)

**Streaming Results (Hybrid):**
```bash
# Test ch·∫°y local, k·∫øt qu·∫£ stream l√™n cloud
./k6-v0.52.0-windows-amd64/k6.exe run --out cloud scripts/load-test.js
```

**Cloud Execution:**
```bash
# Test ch·∫°y ho√†n to√†n tr√™n cloud
./k6-v0.52.0-windows-amd64/k6.exe cloud scripts/load-test.js
```

**Features:**
- ‚úÖ Real-time dashboard
- ‚úÖ Historical data & trends
- ‚úÖ Distributed testing t·ª´ nhi·ªÅu zones
- ‚úÖ Automatic insights & recommendations
- ‚úÖ Team collaboration
- ‚úÖ Scheduled tests
- ‚úÖ Webhook notifications

**Cost:**
- Free tier: 50 VUh/month
- Pro: $49/month - 1000 VUh
- Enterprise: Custom pricing

**Xem chi ti·∫øt:** [k6-cloud-integration.md](./k6-cloud-integration.md)

#### C. InfluxDB + Grafana (Self-hosted)

**Setup:**
```bash
# 1. Start InfluxDB
docker run -d -p 8086:8086 influxdb:1.8

# 2. Create K6 database
curl -XPOST 'http://localhost:8086/query' --data-urlencode 'q=CREATE DATABASE k6'

# 3. Run test with InfluxDB output
./k6-v0.52.0-windows-amd64/k6.exe run \
  --out influxdb=http://localhost:8086/k6 \
  scripts/load-test.js

# 4. Setup Grafana
docker run -d -p 3000:3000 grafana/grafana

# 5. Import K6 dashboard (ID: 2587)
# https://grafana.com/grafana/dashboards/2587
```

**∆Øu ƒëi·ªÉm:**
- ‚úÖ Full control
- ‚úÖ Real-time visualization
- ‚úÖ Powerful querying
- ‚úÖ Unlimited data retention
- ‚úÖ Custom dashboards

**Nh∆∞·ª£c ƒëi·ªÉm:**
- ‚ùå C·∫ßn infrastructure setup
- ‚ùå Maintenance overhead
- ‚ùå Steeper learning curve

#### D. Custom Monitoring Solution (Implemented)

Ch√∫ng ta ƒë√£ x√¢y d·ª±ng custom monitoring stack v·ªõi c√°c components:

**1. Real-time Monitoring Utilities** (`utils/monitoring.js`)
- Custom metrics tracking
- Enhanced thresholds
- Alert configuration
- Metrics formatting

**2. Results Aggregator** (`utils/aggregate-results.js`)
- Parse NDJSON format
- Aggregate multiple test results
- Generate comparison reports
- Identify performance issues
- HTML dashboard generation

**3. Alert Monitor** (`utils/alert-monitor.js`)
- Threshold-based alerting
- Multi-level alerts (Critical, Warning, Info)
- Alert persistence v√† reporting
- HTML alert reports

---

### 4.8.2 Thi·∫øt l·∫≠p Dashboard v√† C·∫£nh b√°o

#### A. Monitoring Dashboard

**File:** `utils/monitoring.js`

**Custom Metrics ƒë√£ implement:**
```javascript
import { Trend, Counter, Gauge, Rate } from 'k6/metrics';

// Response time trends
apiResponseTime: new Trend('api_response_time', true)
petEndpointTime: new Trend('pet_endpoint_time', true)
storeEndpointTime: new Trend('store_endpoint_time', true)

// Error tracking
totalErrors: new Counter('total_errors')
authErrors: new Counter('auth_errors')
serverErrors: new Counter('server_errors')
clientErrors: new Counter('client_errors')

// Success rates
successRate: new Rate('success_rate')
petApiSuccess: new Rate('pet_api_success')

// Current state
activeVUs: new Gauge('active_vus')
currentRPS: new Gauge('current_rps')
```

**Monitoring Thresholds:**
```javascript
export const monitoringThresholds = {
  'http_req_duration': [
    'p(50)<300',   // 50% under 300ms
    'p(90)<500',   // 90% under 500ms
    'p(95)<800',   // 95% under 800ms
    'p(99)<1500',  // 99% under 1.5s
  ],
  'http_req_failed': ['rate<0.05'],  // <5% error rate
  'http_reqs': ['rate>10'],           // >10 req/s
  'checks': ['rate>0.90'],            // >90% checks pass
  'success_rate': ['rate>0.95'],      // >95% success
}
```

#### B. Aggregated Results Dashboard

**Script:** `utils/aggregate-results.js`

**Ch·ª©c nƒÉng:**
1. ƒê·ªçc t·∫•t c·∫£ test results t·ª´ `results/` directory
2. Parse NDJSON format
3. T√≠nh to√°n aggregate statistics
4. Generate comparison table
5. Identify performance issues
6. T·∫°o HTML dashboard

**C√°ch ch·∫°y:**
```bash
node utils/aggregate-results.js
```

**Output:**
```
üìä Aggregating K6 test results...

‚úÖ Found 6 test results

‚úÖ JSON report saved to: results/aggregated-report.json
‚úÖ HTML dashboard saved to: results/monitoring-dashboard.html

============================================================
SUMMARY
============================================================
Total Tests: 6
Total Requests: 8,845
Avg Response Time: 260.65ms
Avg Error Rate: 31.04%
Avg Checks Pass Rate: 95.99%
Issues Found: 8
============================================================
```

**Dashboard Features:**
- üìä Statistics cards (Total tests, requests, response time, error rate)
- üìà Comparison table across all tests
- ‚ö†Ô∏è Issues & alerts section
- üé® Beautiful, responsive design
- üì± Mobile-friendly

**Screenshot m√¥ t·∫£:**
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ        K6 Performance Monitoring Dashboard              ‚îÇ
‚îÇ            Generated: 2025-11-24 08:30:15               ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê‚îÇ
‚îÇ  ‚îÇ Total  ‚îÇ ‚îÇ Total  ‚îÇ ‚îÇ  Avg   ‚îÇ ‚îÇ  Avg   ‚îÇ ‚îÇ  Avg   ‚îÇ‚îÇ
‚îÇ  ‚îÇ Tests  ‚îÇ ‚îÇRequest ‚îÇ ‚îÇResponse‚îÇ ‚îÇ Error  ‚îÇ ‚îÇ Checks ‚îÇ‚îÇ
‚îÇ  ‚îÇ   6    ‚îÇ ‚îÇ 8,845  ‚îÇ ‚îÇ 260ms  ‚îÇ ‚îÇ 31.04% ‚îÇ ‚îÇ 95.99% ‚îÇ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  Test Results Comparison                                ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ Test Name    ‚îÇ Requests ‚îÇ Error Rate ‚îÇ Avg Time ‚îÇ   ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§   ‚îÇ
‚îÇ  ‚îÇ load-test    ‚îÇ 2,761    ‚îÇ 48.18%     ‚îÇ 251ms    ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ stress-test  ‚îÇ 3,373    ‚îÇ 54.11%     ‚îÇ 237ms    ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ spike-test   ‚îÇ 2,108    ‚îÇ 63.93%     ‚îÇ 234ms    ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  ‚ö†Ô∏è Issues & Alerts                                     ‚îÇ
‚îÇ  üî¥ High error rate: load-test (48.18%)                 ‚îÇ
‚îÇ  üî¥ High error rate: stress-test (54.11%)               ‚îÇ
‚îÇ  üî¥ High error rate: spike-test (63.93%)                ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

#### C. Alerting System

**Script:** `utils/alert-monitor.js`

**Alert Thresholds:**
```javascript
const ALERT_THRESHOLDS = {
  responseTime: {
    warning: 500,      // ms
    critical: 1000,    // ms
  },
  errorRate: {
    warning: 5,        // %
    critical: 10,      // %
  },
  p95ResponseTime: {
    warning: 1000,     // ms
    critical: 2000,    // ms
  },
  checksPassRate: {
    warning: 90,       // %
    critical: 80,      // %
  },
  throughput: {
    warning: 10,       // req/s
    critical: 5,       // req/s
  },
}
```

**Alert Levels:**
- üî¥ **CRITICAL**: V·∫•n ƒë·ªÅ nghi√™m tr·ªçng c·∫ßn x·ª≠ l√Ω ngay
- ‚ö†Ô∏è **WARNING**: V·∫•n ƒë·ªÅ c·∫ßn theo d√µi
- ‚ÑπÔ∏è **INFO**: Th√¥ng tin tham kh·∫£o

**C√°ch ch·∫°y:**
```bash
node utils/alert-monitor.js
```

**Output:**
```
üîç Monitoring test results for alerts...

======================================================================
ALERTS
======================================================================

üî¥ CRITICAL ALERTS:
  üî¥ [CRITICAL] [load-test] Error rate is critically high
      (Current: 48.18%, Threshold: 10%)
  üî¥ [CRITICAL] [stress-test] Error rate is critically high
      (Current: 54.11%, Threshold: 10%)
  üî¥ [CRITICAL] [spike-test] Error rate is critically high
      (Current: 63.93%, Threshold: 10%)

‚ö†Ô∏è  WARNING ALERTS:
  ‚ö†Ô∏è [WARNING] [auth-test] Throughput is below warning threshold
      (Current: 7.10 req/s, Threshold: 10 req/s)

======================================================================
Total Alerts: 8 (Critical: 6, Warning: 2, Info: 0)
======================================================================

üíæ Alerts saved to: results/alerts.json
üìä HTML alert report saved to: results/alert-report.html
```

**Alert Report Features:**
- JSON format cho automation
- HTML format cho human-readable
- Email/Slack integration ready (c√≥ th·ªÉ extend)
- Historical alert tracking

#### D. Monitored Load Test

**Script:** `scripts/monitored-load-test.js`

ƒê√¢y l√† example script t√≠ch h·ª£p ƒë·∫ßy ƒë·ªß monitoring features:

**Custom Metrics:**
```javascript
const petApiSuccess = new Rate('pet_api_success_rate');
const storeApiSuccess = new Rate('store_api_success_rate');
const apiResponseTime = new Trend('api_response_time_ms');
const errorsByType = new Counter('errors_by_type');
const slowRequests = new Counter('slow_requests_count');
```

**Monitored Request Function:**
```javascript
function monitoredRequest(url, params, endpoint) {
  const startTime = new Date().getTime();
  const response = http.get(url, params);
  const duration = new Date().getTime() - startTime;

  // Record metrics
  apiResponseTime.add(duration);

  // Track slow requests
  if (duration > 1000) {
    slowRequests.add(1);
    console.warn(`‚ö†Ô∏è Slow request: ${endpoint} took ${duration}ms`);
  }

  // Track success rates
  const isSuccess = response.status >= 200 && response.status < 300;
  if (endpoint.includes('pet')) {
    petApiSuccess.add(isSuccess);
  }

  // Track errors by type
  if (!isSuccess) {
    errorsByType.add(1, { error_code: response.status });
    console.error(`‚ùå Error: ${endpoint} returned ${response.status}`);
  }

  return { response, duration, isSuccess };
}
```

**Custom Summary Handler:**
```javascript
export function handleSummary(data) {
  const stats = {
    testRun: { /* ... */ },
    requests: { /* ... */ },
    responseTime: { /* ... */ },
    customMetrics: {
      petApiSuccessRate: '...',
      storeApiSuccessRate: '...',
      avgApiResponseTime: '...',
      totalErrors: '...',
      slowRequests: '...',
    }
  };

  console.log(JSON.stringify(stats, null, 2));

  return {
    'stdout': '',
    'results/monitored-load-test.json': JSON.stringify(data, null, 2),
  };
}
```

**Ch·∫°y test:**
```bash
./k6-v0.52.0-windows-amd64/k6.exe run scripts/monitored-load-test.js
```

---

## üìä K·∫æT QU·∫¢ TH·ª∞C T·∫æ

### Generated Files

Sau khi ch·∫°y ƒë·∫ßy ƒë·ªß monitoring system, c√°c files ƒë∆∞·ª£c t·∫°o ra:

```
results/
‚îú‚îÄ‚îÄ aggregated-report.json       # T·ªïng h·ª£p t·∫•t c·∫£ test results
‚îú‚îÄ‚îÄ monitoring-dashboard.html    # Interactive dashboard
‚îú‚îÄ‚îÄ alerts.json                  # Alert data (JSON)
‚îú‚îÄ‚îÄ alert-report.html           # Alert report (HTML)
‚îî‚îÄ‚îÄ monitored-load-test.json    # Monitored test results
```

### Dashboard Screenshots

**1. Monitoring Dashboard** (`results/monitoring-dashboard.html`)
- Responsive design
- Real-time statistics
- Performance comparison table
- Issues highlighting

**2. Alert Report** (`results/alert-report.html`)
- Critical alerts at top
- Color-coded severity
- Detailed metrics
- Timestamp tracking

### Performance Analysis t·ª´ Aggregated Report

**T·ªïng quan:**
- Total Tests: 6
- Total Requests: 8,845
- Avg Response Time: 260.65ms
- Avg Error Rate: 31.04% ‚ö†Ô∏è
- Avg Checks Pass Rate: 95.99%

**V·∫•n ƒë·ªÅ ph√°t hi·ªán:**
1. **High Error Rate** tr√™n t·∫•t c·∫£ tests
   - Root cause: Petstore API kh√¥ng stable
   - Nhi·ªÅu 404 errors do pet IDs kh√¥ng t·ªìn t·∫°i
   - Recommendation: S·ª≠ d·ª•ng valid pet IDs ho·∫∑c t·∫°o pets tr∆∞·ªõc khi test

2. **Low Throughput** tr√™n m·ªôt s·ªë tests
   - C√≥ th·ªÉ do API rate limiting
   - Ho·∫∑c network latency

3. **Response Time** ·ªïn ƒë·ªãnh
   - Avg ~260ms l√† acceptable
   - P95 < 1s l√† t·ªët

---

## üéØ BEST PRACTICES

### 1. Monitoring Strategy

**Ph√¢n t√≠ch theo layers:**
```
Layer 1: Infrastructure Metrics
  ‚îî‚îÄ> VUs, Memory, CPU

Layer 2: HTTP Metrics
  ‚îî‚îÄ> Request rate, Response time, Errors

Layer 3: Business Metrics
  ‚îî‚îÄ> Success rate, User workflows, Conversions

Layer 4: Alerts
  ‚îî‚îÄ> Threshold violations, Anomalies
```

### 2. Alert Configuration

**Thi·∫øt l·∫≠p thresholds h·ª£p l√Ω:**
- D·ª±a tr√™n baseline performance
- Test trong m√¥i tr∆∞·ªùng t∆∞∆°ng t·ª± production
- Tr√°nh false positives
- ∆Øu ti√™n critical alerts

**Example:**
```javascript
// ‚ùå BAD: Too strict
thresholds: {
  'http_req_duration': ['p(95)<100'],  // Kh√¥ng realistic
}

// ‚úÖ GOOD: Reasonable
thresholds: {
  'http_req_duration': ['p(95)<500', 'p(99)<1000'],
  'http_req_failed': ['rate<0.05'],
}
```

### 3. Dashboard Design

**Nguy√™n t·∫Øc:**
- **At-a-glance**: Th√¥ng tin quan tr·ªçng nh·∫•t ·ªü top
- **Drill-down**: Chi ti·∫øt h∆°n ·ªü d∆∞·ªõi
- **Color coding**: üî¥ Critical, ‚ö†Ô∏è Warning, ‚úÖ OK
- **Trends**: So s√°nh v·ªõi tests tr∆∞·ªõc
- **Context**: Th√™m annotations (deployments, incidents)

### 4. Automation Workflow

**Suggested pipeline:**
```bash
# 1. Run all tests
./k6-v0.52.0-windows-amd64/k6.exe run --out json=results/test1.json scripts/test1.js
./k6-v0.52.0-windows-amd64/k6.exe run --out json=results/test2.json scripts/test2.js

# 2. Aggregate results
node utils/aggregate-results.js

# 3. Check alerts
node utils/alert-monitor.js

# 4. Send notifications (if alerts)
# ./send-slack-notification.sh results/alerts.json
```

### 5. Data Retention

**Recommendations:**
- **Raw data**: 30 days (NDJSON files)
- **Aggregated reports**: 90 days
- **Summary stats**: 1 year
- **Alerts history**: 6 months

---

## üîß TROUBLESHOOTING

### Issue 1: Large JSON Files

**Problem:** Test results qu√° l·ªõn (>100MB)

**Solutions:**
```bash
# Option 1: Reduce sampling rate
./k6-v0.52.0-windows-amd64/k6.exe run --out json=results/test.json \
  --summary-trend-stats="min,avg,max,p(95),p(99)" \
  scripts/test.js

# Option 2: Use compression
./k6-v0.52.0-windows-amd64/k6.exe run --out json=results/test.json.gz scripts/test.js

# Option 3: Stream to backend instead of file
./k6-v0.52.0-windows-amd64/k6.exe run --out influxdb=http://localhost:8086/k6 scripts/test.js
```

### Issue 2: Parsing Errors

**Problem:** NDJSON parsing fails

**Check:**
1. File encoding (UTF-8)
2. Newline characters (LF vs CRLF)
3. Incomplete JSON objects (test interrupted)

**Fix:**
```javascript
// Robust parsing
lines.forEach(line => {
  try {
    const entry = JSON.parse(line);
    // Process entry
  } catch (e) {
    console.warn(`Skipping invalid line: ${line.substring(0, 50)}...`);
  }
});
```

### Issue 3: Dashboard kh√¥ng hi·ªÉn th·ªã ƒë√∫ng

**Check:**
1. Browser console errors
2. Data format
3. File paths
4. Chart library loaded

---

## üìö T√ÄI LI·ªÜU THAM KH·∫¢O

### Official Documentation
- K6 Cloud: https://k6.io/docs/cloud/
- K6 Outputs: https://k6.io/docs/results-output/
- K6 Metrics: https://k6.io/docs/using-k6/metrics/

### Dashboards & Templates
- Grafana K6 Dashboard: https://grafana.com/grafana/dashboards/2587
- K6 Public Tests: https://app.k6.io/public

### Integration Guides
- InfluxDB: https://k6.io/docs/results-output/real-time/influxdb/
- Prometheus: https://k6.io/docs/results-output/real-time/prometheus-remote-write/
- Datadog: https://k6.io/docs/results-output/real-time/datadog/

---

## ‚úÖ CHECKLIST HO√ÄN TH√ÄNH PHASE 5

### Monitoring Setup
- [x] Custom metrics implementation
- [x] Monitoring utilities
- [x] NDJSON parser
- [x] Results aggregator
- [x] HTML dashboard generator

### Alerting System
- [x] Alert thresholds configuration
- [x] Multi-level alerts (Critical/Warning/Info)
- [x] Alert monitoring script
- [x] JSON alert export
- [x] HTML alert report

### Integration & Documentation
- [x] K6 Cloud integration guide
- [x] Monitored load test example
- [x] Dashboard screenshots
- [x] Best practices documentation
- [x] Troubleshooting guide

### Deliverables
- [x] `utils/monitoring.js` - Monitoring utilities
- [x] `utils/aggregate-results.js` - Results aggregator
- [x] `utils/alert-monitor.js` - Alert monitoring
- [x] `scripts/monitored-load-test.js` - Monitored test example
- [x] `docs/k6-cloud-integration.md` - K6 Cloud guide
- [x] `docs/phase5-monitoring-automation-report.md` - This report
- [x] `results/monitoring-dashboard.html` - Interactive dashboard
- [x] `results/alert-report.html` - Alert report

---

## üéì K·∫æT LU·∫¨N

Phase 5 ƒë√£ ho√†n th√†nh th√†nh c√¥ng v·ªõi h·ªá th·ªëng monitoring v√† automation to√†n di·ªán:

**Th√†nh t·ª±u ch√≠nh:**
1. ‚úÖ Custom monitoring solution ho√†n ch·ªânh
2. ‚úÖ Automated aggregation v√† reporting
3. ‚úÖ Intelligent alerting system
4. ‚úÖ Beautiful, responsive dashboards
5. ‚úÖ Comprehensive documentation

**L·ª£i √≠ch:**
- üìä **Visibility**: Nh√¨n th·∫•y performance metrics real-time
- üö® **Proactive**: Ph√°t hi·ªán issues s·ªõm qua alerts
- üìà **Trends**: So s√°nh performance qua th·ªùi gian
- ü§ñ **Automation**: Gi·∫£m manual work
- üìù **Documentation**: D·ªÖ onboard team members m·ªõi

**Next Steps:**
1. Integrate v√†o CI/CD pipeline
2. Setup scheduled tests
3. Implement notification webhooks (Slack, Email)
4. Add performance budgets
5. Create performance regression tests

**T·ªïng th·ªùi gian Phase 5:** ~3 gi·ªù (theo k·∫ø ho·∫°ch: 2-3 gi·ªù) ‚úÖ

---

*B√°o c√°o ƒë∆∞·ª£c t·∫°o: 2025-11-24*
*D·ª± √°n: K6 Performance Testing cho Petstore API*
*Phase: 5/5 - Monitoring & Automation*
